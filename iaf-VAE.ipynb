{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rolled-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "danish-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "willing-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "eval_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "eval_loader = torch.utils.data.DataLoader(dataset=eval_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "helpful-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IAF_Layer(nn.Module):\n",
    "    def __init__(self,  input_dim, hidden_dim, out_dim, reverse=False):\n",
    "        super(IAF_Layer, self).__init__()\n",
    "        \n",
    "        self.m_layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "            )\n",
    "        self.s_layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "            )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.reverse = reverse\n",
    "    \n",
    "    def forward(self, z, h):\n",
    "        \n",
    "#         print(z.shape)\n",
    "#         exit()\n",
    "#         if self.reverse:\n",
    "#             z =  torch.flip(z, dims=-1)\n",
    "        \n",
    "        iaf_input = torch.cat([z, h], dim=-1)\n",
    "        m = self.m_layer(iaf_input)\n",
    "        s = self.s_layer(iaf_input)\n",
    "        sigma = self.sigmoid(s)\n",
    "    \n",
    "        return z * sigma + m * (1. - sigma), sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cardiovascular-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IAF_VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h1, h2, z_dim, num_iaf):\n",
    "        super(IAF_VAE, self).__init__()\n",
    "        \n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(x_dim, h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h1, h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h2, z_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.enc_mu = nn.Linear(z_dim, z_dim)\n",
    "        self.enc_log_var = nn.Linear(z_dim, z_dim)\n",
    "        \n",
    "        iaf_layers = []\n",
    "        for i in range(num_iaf):\n",
    "            reverse = i > 0 \n",
    "            iaf_layers.append(IAF_Layer(z_dim*2, z_dim*2, z_dim, reverse=reverse))\n",
    "        self.iaf_layers = nn.ModuleList(iaf_layers)\n",
    "        \n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Linear(z_dim, h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h2, h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h1, x_dim),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # original z_0\n",
    "        h = self.enc(x)\n",
    "        mu, log_var = self.enc_mu(h), self.enc_log_var(h)\n",
    "        z_0, eps_0 = self.sampling(mu, log_var)\n",
    "        \n",
    "        z_t = z_0\n",
    "        z_sigmas = []\n",
    "        \n",
    "        # iaf flows \n",
    "        for iaf in self.iaf_layers:\n",
    "            z_t, sigma_z_t = iaf(z_t, h)\n",
    "            z_sigmas.append(sigma_z_t)\n",
    "        \n",
    "        z = z_t \n",
    "        \n",
    "        return self.dec(z), mu, log_var, z_sigmas, eps_0, z\n",
    "        \n",
    "    def sampling(self, mu, log_var):\n",
    "        # reparametrization trick\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.rand_like(std)\n",
    "        return mu + (eps * std), eps\n",
    "\n",
    "vae = IAF_VAE(x_dim=784, h1=512, h2=256, z_dim=2, num_iaf=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prepared-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sample = torch.randn(10, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "based-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, mu, log_var, z_sigmas, eps_0, z_t = vae(input_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "massive-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x, mu, log_var, z_sigmas, eps_0, z):\n",
    "    # reconstruction loss : binary cross entropy \n",
    "    # logp(x|z)\n",
    "    bce_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    \n",
    "    # -logp(z)\n",
    "    logpz = torch.sum(0.5 * np.log(2*math.pi) + 0.5*z**2)\n",
    "    \n",
    "    # logq(z|x)\n",
    "    det = log_var \n",
    "    for z_sigma in z_sigmas:\n",
    "        det += torch.log(z_sigma)\n",
    "    logqz_x = torch.sum(0.5 * np.log(2*math.pi) +0.5*eps_0**2 + det)\n",
    "    \n",
    "    return bce_loss + logpz - logqz_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "generic-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(vae.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excellent-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_ind, (data, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.view(BATCH_SIZE, -1)\n",
    "        recon_x, mu, log_var, z_sigmas, eps_0, z_t = vae(data)\n",
    "        loss = loss_fn(recon_x, data, mu, log_var, z_sigmas, eps_0, z_t)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_ind % 200 == 0:\n",
    "            print('Train Epoch:{} [{}/{} ({:0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_ind*len(data), len(train_loader.dataset),\n",
    "                100*batch_ind/len(train_loader), loss.item()/len(data)))\n",
    "        \n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss/len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "intelligent-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(): \n",
    "    vae.eval()\n",
    "    eval_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in eval_loader:\n",
    "#             data = data.cuda()\n",
    "            data = data.view(BATCH_SIZE, -1)\n",
    "            recon_x, mu, log_var, z_sigmas, eps_0, z_t = vae(data)\n",
    "            eval_loss += loss_fn(recon_x, data, mu, log_var, z_sigmas, eps_0, z_t)\n",
    "            \n",
    "    eval_loss /= len(eval_loader.dataset)\n",
    "    print('====> Evaluation loss : {:.4f}'.format(eval_loss))   \n",
    "    return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "foster-demand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:1 [0/60000 (0.000000%)]\tLoss: 549.676680\n",
      "Train Epoch:1 [20000/60000 (33.333333%)]\tLoss: 188.982480\n",
      "Train Epoch:1 [40000/60000 (66.666667%)]\tLoss: 185.670273\n",
      "====> Epoch: 1 Average loss: 191.6321\n",
      "====> Evaluation loss : 177.9373\n",
      "Train Epoch:2 [0/60000 (0.000000%)]\tLoss: 180.321699\n",
      "Train Epoch:2 [20000/60000 (33.333333%)]\tLoss: 178.761211\n",
      "Train Epoch:2 [40000/60000 (66.666667%)]\tLoss: 168.771289\n",
      "====> Epoch: 2 Average loss: 173.9770\n",
      "====> Evaluation loss : 169.2890\n",
      "Train Epoch:3 [0/60000 (0.000000%)]\tLoss: 170.882656\n",
      "Train Epoch:3 [20000/60000 (33.333333%)]\tLoss: 171.793438\n",
      "Train Epoch:3 [40000/60000 (66.666667%)]\tLoss: 167.121563\n",
      "====> Epoch: 3 Average loss: 167.3482\n",
      "====> Evaluation loss : 163.7703\n",
      "Train Epoch:4 [0/60000 (0.000000%)]\tLoss: 164.443945\n",
      "Train Epoch:4 [20000/60000 (33.333333%)]\tLoss: 155.803955\n",
      "Train Epoch:4 [40000/60000 (66.666667%)]\tLoss: 152.185020\n",
      "====> Epoch: 4 Average loss: 162.1096\n",
      "====> Evaluation loss : 160.1425\n",
      "Train Epoch:5 [0/60000 (0.000000%)]\tLoss: 159.363115\n",
      "Train Epoch:5 [20000/60000 (33.333333%)]\tLoss: 164.271348\n",
      "Train Epoch:5 [40000/60000 (66.666667%)]\tLoss: 165.427969\n",
      "====> Epoch: 5 Average loss: 159.0530\n",
      "====> Evaluation loss : 156.2436\n",
      "Train Epoch:6 [0/60000 (0.000000%)]\tLoss: 152.675605\n",
      "Train Epoch:6 [20000/60000 (33.333333%)]\tLoss: 153.769170\n",
      "Train Epoch:6 [40000/60000 (66.666667%)]\tLoss: 158.787324\n",
      "====> Epoch: 6 Average loss: 157.1101\n",
      "====> Evaluation loss : 156.4203\n",
      "Train Epoch:7 [0/60000 (0.000000%)]\tLoss: 163.963086\n",
      "Train Epoch:7 [20000/60000 (33.333333%)]\tLoss: 153.444277\n",
      "Train Epoch:7 [40000/60000 (66.666667%)]\tLoss: 152.302305\n",
      "====> Epoch: 7 Average loss: 154.2788\n",
      "====> Evaluation loss : 152.7498\n",
      "Train Epoch:8 [0/60000 (0.000000%)]\tLoss: 152.263633\n",
      "Train Epoch:8 [20000/60000 (33.333333%)]\tLoss: 155.222715\n",
      "Train Epoch:8 [40000/60000 (66.666667%)]\tLoss: 142.840254\n",
      "====> Epoch: 8 Average loss: 154.6109\n",
      "====> Evaluation loss : 169.0733\n",
      "Train Epoch:9 [0/60000 (0.000000%)]\tLoss: 178.690254\n",
      "Train Epoch:9 [20000/60000 (33.333333%)]\tLoss: 153.738750\n",
      "Train Epoch:9 [40000/60000 (66.666667%)]\tLoss: 153.288330\n",
      "====> Epoch: 9 Average loss: 155.2323\n",
      "====> Evaluation loss : 151.5990\n",
      "Train Epoch:10 [0/60000 (0.000000%)]\tLoss: 148.639189\n",
      "Train Epoch:10 [20000/60000 (33.333333%)]\tLoss: 147.009316\n",
      "Train Epoch:10 [40000/60000 (66.666667%)]\tLoss: 152.960781\n",
      "====> Epoch: 10 Average loss: 153.1188\n",
      "====> Evaluation loss : 151.7772\n",
      "Train Epoch:11 [0/60000 (0.000000%)]\tLoss: 151.221953\n",
      "Train Epoch:11 [20000/60000 (33.333333%)]\tLoss: 154.280742\n",
      "Train Epoch:11 [40000/60000 (66.666667%)]\tLoss: 141.456377\n",
      "====> Epoch: 11 Average loss: 151.6051\n",
      "====> Evaluation loss : 150.5365\n",
      "Train Epoch:12 [0/60000 (0.000000%)]\tLoss: 142.807129\n",
      "Train Epoch:12 [20000/60000 (33.333333%)]\tLoss: 155.489785\n",
      "Train Epoch:12 [40000/60000 (66.666667%)]\tLoss: 145.074609\n",
      "====> Epoch: 12 Average loss: 150.7840\n",
      "====> Evaluation loss : 149.0562\n",
      "Train Epoch:13 [0/60000 (0.000000%)]\tLoss: 150.554834\n",
      "Train Epoch:13 [20000/60000 (33.333333%)]\tLoss: 155.332920\n",
      "Train Epoch:13 [40000/60000 (66.666667%)]\tLoss: 183.875254\n",
      "====> Epoch: 13 Average loss: 160.5655\n",
      "====> Evaluation loss : 163.4624\n",
      "Train Epoch:14 [0/60000 (0.000000%)]\tLoss: 166.868672\n",
      "Train Epoch:14 [20000/60000 (33.333333%)]\tLoss: 161.643018\n",
      "Train Epoch:14 [40000/60000 (66.666667%)]\tLoss: 151.442637\n",
      "====> Epoch: 14 Average loss: 159.5008\n",
      "====> Evaluation loss : 153.8279\n",
      "Train Epoch:15 [0/60000 (0.000000%)]\tLoss: 154.797910\n",
      "Train Epoch:15 [20000/60000 (33.333333%)]\tLoss: 154.888359\n",
      "Train Epoch:15 [40000/60000 (66.666667%)]\tLoss: 153.050518\n",
      "====> Epoch: 15 Average loss: 154.3023\n",
      "====> Evaluation loss : 151.4947\n",
      "Train Epoch:16 [0/60000 (0.000000%)]\tLoss: 147.217842\n",
      "Train Epoch:16 [20000/60000 (33.333333%)]\tLoss: 165.576055\n",
      "Train Epoch:16 [40000/60000 (66.666667%)]\tLoss: 140.565439\n",
      "====> Epoch: 16 Average loss: 152.6376\n",
      "====> Evaluation loss : 150.3374\n",
      "Train Epoch:17 [0/60000 (0.000000%)]\tLoss: 150.375127\n",
      "Train Epoch:17 [20000/60000 (33.333333%)]\tLoss: 199.823574\n",
      "Train Epoch:17 [40000/60000 (66.666667%)]\tLoss: 167.428242\n",
      "====> Epoch: 17 Average loss: 179.1655\n",
      "====> Evaluation loss : 170.5761\n",
      "Train Epoch:18 [0/60000 (0.000000%)]\tLoss: 168.421680\n",
      "Train Epoch:18 [20000/60000 (33.333333%)]\tLoss: 169.281016\n",
      "Train Epoch:18 [40000/60000 (66.666667%)]\tLoss: 162.589824\n",
      "====> Epoch: 18 Average loss: 164.1470\n",
      "====> Evaluation loss : 163.7564\n",
      "Train Epoch:19 [0/60000 (0.000000%)]\tLoss: 173.452344\n",
      "Train Epoch:19 [20000/60000 (33.333333%)]\tLoss: 164.484238\n",
      "Train Epoch:19 [40000/60000 (66.666667%)]\tLoss: 164.831250\n",
      "====> Epoch: 19 Average loss: 160.5806\n",
      "====> Evaluation loss : 157.6114\n",
      "Train Epoch:20 [0/60000 (0.000000%)]\tLoss: 161.440752\n",
      "Train Epoch:20 [20000/60000 (33.333333%)]\tLoss: 163.192285\n",
      "Train Epoch:20 [40000/60000 (66.666667%)]\tLoss: 153.942168\n",
      "====> Epoch: 20 Average loss: 158.0459\n",
      "====> Evaluation loss : 155.3598\n",
      "Train Epoch:21 [0/60000 (0.000000%)]\tLoss: 158.851211\n",
      "Train Epoch:21 [20000/60000 (33.333333%)]\tLoss: 153.944297\n",
      "Train Epoch:21 [40000/60000 (66.666667%)]\tLoss: 144.950020\n",
      "====> Epoch: 21 Average loss: 154.7576\n",
      "====> Evaluation loss : 152.4669\n",
      "Train Epoch:22 [0/60000 (0.000000%)]\tLoss: 154.234023\n",
      "Train Epoch:22 [20000/60000 (33.333333%)]\tLoss: 147.255840\n",
      "Train Epoch:22 [40000/60000 (66.666667%)]\tLoss: 150.516230\n",
      "====> Epoch: 22 Average loss: 152.6298\n",
      "====> Evaluation loss : 150.8003\n",
      "Train Epoch:23 [0/60000 (0.000000%)]\tLoss: 146.158691\n",
      "Train Epoch:23 [20000/60000 (33.333333%)]\tLoss: 188.377480\n",
      "Train Epoch:23 [40000/60000 (66.666667%)]\tLoss: 157.064180\n",
      "====> Epoch: 23 Average loss: 157.7118\n",
      "====> Evaluation loss : 151.1765\n",
      "Train Epoch:24 [0/60000 (0.000000%)]\tLoss: 141.770332\n",
      "Train Epoch:24 [20000/60000 (33.333333%)]\tLoss: 172.279492\n",
      "Train Epoch:24 [40000/60000 (66.666667%)]\tLoss: 159.702646\n",
      "====> Epoch: 24 Average loss: 158.1969\n",
      "====> Evaluation loss : 152.3542\n",
      "Train Epoch:25 [0/60000 (0.000000%)]\tLoss: 144.274902\n",
      "Train Epoch:25 [20000/60000 (33.333333%)]\tLoss: 152.388223\n",
      "Train Epoch:25 [40000/60000 (66.666667%)]\tLoss: 161.394033\n",
      "====> Epoch: 25 Average loss: 157.0786\n",
      "====> Evaluation loss : 151.7200\n",
      "Train Epoch:26 [0/60000 (0.000000%)]\tLoss: 149.684082\n",
      "Train Epoch:26 [20000/60000 (33.333333%)]\tLoss: 161.002285\n",
      "Train Epoch:26 [40000/60000 (66.666667%)]\tLoss: 162.760908\n",
      "====> Epoch: 26 Average loss: 208.6974\n",
      "====> Evaluation loss : 164.6991\n",
      "Train Epoch:27 [0/60000 (0.000000%)]\tLoss: 161.065205\n",
      "Train Epoch:27 [20000/60000 (33.333333%)]\tLoss: 166.728691\n",
      "Train Epoch:27 [40000/60000 (66.666667%)]\tLoss: 152.550967\n",
      "====> Epoch: 27 Average loss: 157.6369\n",
      "====> Evaluation loss : 152.6158\n",
      "Train Epoch:28 [0/60000 (0.000000%)]\tLoss: 154.365234\n",
      "Train Epoch:28 [20000/60000 (33.333333%)]\tLoss: 149.149785\n",
      "Train Epoch:28 [40000/60000 (66.666667%)]\tLoss: 151.581895\n",
      "====> Epoch: 28 Average loss: 152.3669\n",
      "====> Evaluation loss : 150.3986\n",
      "Train Epoch:29 [0/60000 (0.000000%)]\tLoss: 139.560449\n",
      "Train Epoch:29 [20000/60000 (33.333333%)]\tLoss: 156.533203\n",
      "Train Epoch:29 [40000/60000 (66.666667%)]\tLoss: 168.459277\n",
      "====> Epoch: 29 Average loss: 151.9529\n",
      "====> Evaluation loss : 150.0596\n",
      "Train Epoch:30 [0/60000 (0.000000%)]\tLoss: 148.288496\n",
      "Train Epoch:30 [20000/60000 (33.333333%)]\tLoss: 147.368154\n",
      "Train Epoch:30 [40000/60000 (66.666667%)]\tLoss: 147.823496\n",
      "====> Epoch: 30 Average loss: 149.6514\n",
      "====> Evaluation loss : 148.7414\n",
      "Train Epoch:31 [0/60000 (0.000000%)]\tLoss: 154.592910\n",
      "Train Epoch:31 [20000/60000 (33.333333%)]\tLoss: 138.871182\n",
      "Train Epoch:31 [40000/60000 (66.666667%)]\tLoss: 150.976484\n",
      "====> Epoch: 31 Average loss: 151.7096\n",
      "====> Evaluation loss : 152.4309\n",
      "Train Epoch:32 [0/60000 (0.000000%)]\tLoss: 153.571260\n",
      "Train Epoch:32 [20000/60000 (33.333333%)]\tLoss: 150.793447\n",
      "Train Epoch:32 [40000/60000 (66.666667%)]\tLoss: 159.518066\n",
      "====> Epoch: 32 Average loss: 154.0455\n",
      "====> Evaluation loss : 151.5507\n",
      "Train Epoch:33 [0/60000 (0.000000%)]\tLoss: 142.869561\n",
      "Train Epoch:33 [20000/60000 (33.333333%)]\tLoss: 156.332109\n",
      "Train Epoch:33 [40000/60000 (66.666667%)]\tLoss: 159.107969\n",
      "====> Epoch: 33 Average loss: 151.3248\n",
      "====> Evaluation loss : 155.6537\n",
      "Train Epoch:34 [0/60000 (0.000000%)]\tLoss: 154.954873\n",
      "Train Epoch:34 [20000/60000 (33.333333%)]\tLoss: 152.855078\n",
      "Train Epoch:34 [40000/60000 (66.666667%)]\tLoss: 147.977783\n",
      "====> Epoch: 34 Average loss: 149.9569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Evaluation loss : 148.5002\n",
      "Train Epoch:35 [0/60000 (0.000000%)]\tLoss: 143.940605\n",
      "Train Epoch:35 [20000/60000 (33.333333%)]\tLoss: 145.012432\n",
      "Train Epoch:35 [40000/60000 (66.666667%)]\tLoss: 144.996094\n",
      "====> Epoch: 35 Average loss: 149.3624\n",
      "====> Evaluation loss : 148.3037\n",
      "Train Epoch:36 [0/60000 (0.000000%)]\tLoss: 146.740137\n",
      "Train Epoch:36 [20000/60000 (33.333333%)]\tLoss: 169.808418\n",
      "Train Epoch:36 [40000/60000 (66.666667%)]\tLoss: 143.752813\n",
      "====> Epoch: 36 Average loss: 151.4378\n",
      "====> Evaluation loss : 148.5747\n",
      "Train Epoch:37 [0/60000 (0.000000%)]\tLoss: 151.506494\n",
      "Train Epoch:37 [20000/60000 (33.333333%)]\tLoss: 140.557920\n",
      "Train Epoch:37 [40000/60000 (66.666667%)]\tLoss: 142.052051\n",
      "====> Epoch: 37 Average loss: 147.6577\n",
      "====> Evaluation loss : 145.9325\n",
      "Train Epoch:38 [0/60000 (0.000000%)]\tLoss: 159.409443\n",
      "Train Epoch:38 [20000/60000 (33.333333%)]\tLoss: 153.887002\n",
      "Train Epoch:38 [40000/60000 (66.666667%)]\tLoss: 150.508398\n",
      "====> Epoch: 38 Average loss: 150.8191\n",
      "====> Evaluation loss : 146.1888\n",
      "Train Epoch:39 [0/60000 (0.000000%)]\tLoss: 149.572188\n",
      "Train Epoch:39 [20000/60000 (33.333333%)]\tLoss: 152.840527\n",
      "Train Epoch:39 [40000/60000 (66.666667%)]\tLoss: 154.527197\n",
      "====> Epoch: 39 Average loss: 146.4305\n",
      "====> Evaluation loss : 145.5900\n",
      "Train Epoch:40 [0/60000 (0.000000%)]\tLoss: 141.708633\n",
      "Train Epoch:40 [20000/60000 (33.333333%)]\tLoss: 144.197207\n",
      "Train Epoch:40 [40000/60000 (66.666667%)]\tLoss: 141.895234\n",
      "====> Epoch: 40 Average loss: 146.2857\n",
      "====> Evaluation loss : 146.0723\n",
      "Train Epoch:41 [0/60000 (0.000000%)]\tLoss: 150.188965\n",
      "Train Epoch:41 [20000/60000 (33.333333%)]\tLoss: 144.393027\n",
      "Train Epoch:41 [40000/60000 (66.666667%)]\tLoss: 143.576543\n",
      "====> Epoch: 41 Average loss: 144.4278\n",
      "====> Evaluation loss : 146.0159\n",
      "Train Epoch:42 [0/60000 (0.000000%)]\tLoss: 147.749121\n",
      "Train Epoch:42 [20000/60000 (33.333333%)]\tLoss: 142.748701\n",
      "Train Epoch:42 [40000/60000 (66.666667%)]\tLoss: 143.858145\n",
      "====> Epoch: 42 Average loss: 148.8314\n",
      "====> Evaluation loss : 159.2484\n",
      "Train Epoch:43 [0/60000 (0.000000%)]\tLoss: 160.312598\n",
      "Train Epoch:43 [20000/60000 (33.333333%)]\tLoss: 135.752793\n",
      "Train Epoch:43 [40000/60000 (66.666667%)]\tLoss: 151.531367\n",
      "====> Epoch: 43 Average loss: 148.4235\n",
      "====> Evaluation loss : 143.9553\n",
      "Train Epoch:44 [0/60000 (0.000000%)]\tLoss: 145.160264\n",
      "Train Epoch:44 [20000/60000 (33.333333%)]\tLoss: 153.332754\n",
      "Train Epoch:44 [40000/60000 (66.666667%)]\tLoss: 144.676777\n",
      "====> Epoch: 44 Average loss: 143.0875\n",
      "====> Evaluation loss : 142.0733\n",
      "Train Epoch:45 [0/60000 (0.000000%)]\tLoss: 139.656172\n",
      "Train Epoch:45 [20000/60000 (33.333333%)]\tLoss: 136.929668\n",
      "Train Epoch:45 [40000/60000 (66.666667%)]\tLoss: 140.979199\n",
      "====> Epoch: 45 Average loss: 142.6440\n",
      "====> Evaluation loss : 140.8592\n",
      "Train Epoch:46 [0/60000 (0.000000%)]\tLoss: 138.872725\n",
      "Train Epoch:46 [20000/60000 (33.333333%)]\tLoss: 139.455059\n",
      "Train Epoch:46 [40000/60000 (66.666667%)]\tLoss: 153.794434\n",
      "====> Epoch: 46 Average loss: 144.6585\n",
      "====> Evaluation loss : 165.2575\n",
      "Train Epoch:47 [0/60000 (0.000000%)]\tLoss: 159.275742\n",
      "Train Epoch:47 [20000/60000 (33.333333%)]\tLoss: 138.031143\n",
      "Train Epoch:47 [40000/60000 (66.666667%)]\tLoss: 148.083389\n",
      "====> Epoch: 47 Average loss: 143.6774\n",
      "====> Evaluation loss : 141.3428\n",
      "Train Epoch:48 [0/60000 (0.000000%)]\tLoss: 143.590557\n",
      "Train Epoch:48 [20000/60000 (33.333333%)]\tLoss: 144.838848\n",
      "Train Epoch:48 [40000/60000 (66.666667%)]\tLoss: 147.438535\n",
      "====> Epoch: 48 Average loss: 140.9831\n",
      "====> Evaluation loss : 140.9707\n",
      "Train Epoch:49 [0/60000 (0.000000%)]\tLoss: 148.410625\n",
      "Train Epoch:49 [20000/60000 (33.333333%)]\tLoss: 143.713232\n",
      "Train Epoch:49 [40000/60000 (66.666667%)]\tLoss: 140.074326\n",
      "====> Epoch: 49 Average loss: 140.8575\n",
      "====> Evaluation loss : 140.2798\n",
      "Train Epoch:50 [0/60000 (0.000000%)]\tLoss: 136.929180\n",
      "Train Epoch:50 [20000/60000 (33.333333%)]\tLoss: 137.537910\n",
      "Train Epoch:50 [40000/60000 (66.666667%)]\tLoss: 139.082197\n",
      "====> Epoch: 50 Average loss: 138.7084\n",
      "====> Evaluation loss : 138.0984\n",
      "Train Epoch:51 [0/60000 (0.000000%)]\tLoss: 131.071689\n",
      "Train Epoch:51 [20000/60000 (33.333333%)]\tLoss: 159.620479\n",
      "Train Epoch:51 [40000/60000 (66.666667%)]\tLoss: 141.654141\n",
      "====> Epoch: 51 Average loss: 144.2297\n",
      "====> Evaluation loss : 137.5636\n",
      "Train Epoch:52 [0/60000 (0.000000%)]\tLoss: 136.356260\n",
      "Train Epoch:52 [20000/60000 (33.333333%)]\tLoss: 135.273105\n",
      "Train Epoch:52 [40000/60000 (66.666667%)]\tLoss: 133.974297\n",
      "====> Epoch: 52 Average loss: 137.9054\n",
      "====> Evaluation loss : 136.9709\n",
      "Train Epoch:53 [0/60000 (0.000000%)]\tLoss: 139.669629\n",
      "Train Epoch:53 [20000/60000 (33.333333%)]\tLoss: 133.826309\n",
      "Train Epoch:53 [40000/60000 (66.666667%)]\tLoss: 138.756172\n",
      "====> Epoch: 53 Average loss: 136.2362\n",
      "====> Evaluation loss : 136.6532\n",
      "Train Epoch:54 [0/60000 (0.000000%)]\tLoss: 144.005498\n",
      "Train Epoch:54 [20000/60000 (33.333333%)]\tLoss: 138.131846\n",
      "Train Epoch:54 [40000/60000 (66.666667%)]\tLoss: 142.365469\n",
      "====> Epoch: 54 Average loss: 137.4224\n",
      "====> Evaluation loss : 137.3300\n",
      "Train Epoch:55 [0/60000 (0.000000%)]\tLoss: 136.213437\n",
      "Train Epoch:55 [20000/60000 (33.333333%)]\tLoss: 134.842646\n",
      "Train Epoch:55 [40000/60000 (66.666667%)]\tLoss: 139.470811\n",
      "====> Epoch: 55 Average loss: 135.0055\n",
      "====> Evaluation loss : 139.1511\n",
      "Train Epoch:56 [0/60000 (0.000000%)]\tLoss: 137.288164\n",
      "Train Epoch:56 [20000/60000 (33.333333%)]\tLoss: 126.957666\n",
      "Train Epoch:56 [40000/60000 (66.666667%)]\tLoss: 138.659365\n",
      "====> Epoch: 56 Average loss: 135.4472\n",
      "====> Evaluation loss : 135.9533\n",
      "Train Epoch:57 [0/60000 (0.000000%)]\tLoss: 143.283301\n",
      "Train Epoch:57 [20000/60000 (33.333333%)]\tLoss: 134.071758\n",
      "Train Epoch:57 [40000/60000 (66.666667%)]\tLoss: 139.537090\n",
      "====> Epoch: 57 Average loss: 135.2797\n",
      "====> Evaluation loss : 134.4405\n",
      "Train Epoch:58 [0/60000 (0.000000%)]\tLoss: 131.481543\n",
      "Train Epoch:58 [20000/60000 (33.333333%)]\tLoss: 127.079824\n",
      "Train Epoch:58 [40000/60000 (66.666667%)]\tLoss: 122.789414\n",
      "====> Epoch: 58 Average loss: 136.3080\n",
      "====> Evaluation loss : 134.4472\n",
      "Train Epoch:59 [0/60000 (0.000000%)]\tLoss: 137.141523\n",
      "Train Epoch:59 [20000/60000 (33.333333%)]\tLoss: 130.879277\n",
      "Train Epoch:59 [40000/60000 (66.666667%)]\tLoss: 125.454316\n",
      "====> Epoch: 59 Average loss: 133.2055\n",
      "====> Evaluation loss : 132.1161\n",
      "Train Epoch:60 [0/60000 (0.000000%)]\tLoss: 131.321816\n",
      "Train Epoch:60 [20000/60000 (33.333333%)]\tLoss: 172.396406\n",
      "Train Epoch:60 [40000/60000 (66.666667%)]\tLoss: 137.321436\n",
      "====> Epoch: 60 Average loss: 138.7451\n",
      "====> Evaluation loss : 135.4488\n",
      "Train Epoch:61 [0/60000 (0.000000%)]\tLoss: 133.004990\n",
      "Train Epoch:61 [20000/60000 (33.333333%)]\tLoss: 130.810059\n",
      "Train Epoch:61 [40000/60000 (66.666667%)]\tLoss: 137.361699\n",
      "====> Epoch: 61 Average loss: 135.7959\n",
      "====> Evaluation loss : 134.0190\n",
      "Train Epoch:62 [0/60000 (0.000000%)]\tLoss: 136.640820\n",
      "Train Epoch:62 [20000/60000 (33.333333%)]\tLoss: 162.432041\n",
      "Train Epoch:62 [40000/60000 (66.666667%)]\tLoss: 160.013486\n",
      "====> Epoch: 62 Average loss: 156.6868\n",
      "====> Evaluation loss : 146.1341\n",
      "Train Epoch:63 [0/60000 (0.000000%)]\tLoss: 145.995391\n",
      "Train Epoch:63 [20000/60000 (33.333333%)]\tLoss: 141.650273\n",
      "Train Epoch:63 [40000/60000 (66.666667%)]\tLoss: 162.860195\n",
      "====> Epoch: 63 Average loss: 161.7121\n",
      "====> Evaluation loss : 154.8299\n",
      "Train Epoch:64 [0/60000 (0.000000%)]\tLoss: 154.179268\n",
      "Train Epoch:64 [20000/60000 (33.333333%)]\tLoss: 152.619053\n",
      "Train Epoch:64 [40000/60000 (66.666667%)]\tLoss: 146.849687\n",
      "====> Epoch: 64 Average loss: 149.1580\n",
      "====> Evaluation loss : 145.2099\n",
      "Train Epoch:65 [0/60000 (0.000000%)]\tLoss: 145.923301\n",
      "Train Epoch:65 [20000/60000 (33.333333%)]\tLoss: 150.123105\n",
      "Train Epoch:65 [40000/60000 (66.666667%)]\tLoss: 150.824551\n",
      "====> Epoch: 65 Average loss: 143.9967\n",
      "====> Evaluation loss : 141.8345\n",
      "Train Epoch:66 [0/60000 (0.000000%)]\tLoss: 143.925225\n",
      "Train Epoch:66 [20000/60000 (33.333333%)]\tLoss: 130.381953\n",
      "Train Epoch:66 [40000/60000 (66.666667%)]\tLoss: 143.442979\n",
      "====> Epoch: 66 Average loss: 141.7455\n",
      "====> Evaluation loss : 139.2293\n",
      "Train Epoch:67 [0/60000 (0.000000%)]\tLoss: 137.543008\n",
      "Train Epoch:67 [20000/60000 (33.333333%)]\tLoss: 147.181699\n",
      "Train Epoch:67 [40000/60000 (66.666667%)]\tLoss: 137.702900\n",
      "====> Epoch: 67 Average loss: 143.7292\n",
      "====> Evaluation loss : 182.5156\n",
      "Train Epoch:68 [0/60000 (0.000000%)]\tLoss: 179.155078\n",
      "Train Epoch:68 [20000/60000 (33.333333%)]\tLoss: 148.974277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:68 [40000/60000 (66.666667%)]\tLoss: 144.755937\n",
      "====> Epoch: 68 Average loss: 157.3677\n",
      "====> Evaluation loss : 149.9432\n",
      "Train Epoch:69 [0/60000 (0.000000%)]\tLoss: 155.387002\n",
      "Train Epoch:69 [20000/60000 (33.333333%)]\tLoss: 143.343203\n",
      "Train Epoch:69 [40000/60000 (66.666667%)]\tLoss: 141.501309\n",
      "====> Epoch: 69 Average loss: 148.5510\n",
      "====> Evaluation loss : 147.2831\n",
      "Train Epoch:70 [0/60000 (0.000000%)]\tLoss: 141.326768\n",
      "Train Epoch:70 [20000/60000 (33.333333%)]\tLoss: 154.369043\n",
      "Train Epoch:70 [40000/60000 (66.666667%)]\tLoss: 168.941641\n",
      "====> Epoch: 70 Average loss: 155.0468\n",
      "====> Evaluation loss : 154.4161\n",
      "Train Epoch:71 [0/60000 (0.000000%)]\tLoss: 158.854766\n",
      "Train Epoch:71 [20000/60000 (33.333333%)]\tLoss: 146.564063\n",
      "Train Epoch:71 [40000/60000 (66.666667%)]\tLoss: 152.551338\n",
      "====> Epoch: 71 Average loss: 148.4194\n",
      "====> Evaluation loss : 143.3674\n",
      "Train Epoch:72 [0/60000 (0.000000%)]\tLoss: 151.759180\n",
      "Train Epoch:72 [20000/60000 (33.333333%)]\tLoss: 142.615703\n",
      "Train Epoch:72 [40000/60000 (66.666667%)]\tLoss: 149.675254\n",
      "====> Epoch: 72 Average loss: 144.4333\n",
      "====> Evaluation loss : 141.3363\n",
      "Train Epoch:73 [0/60000 (0.000000%)]\tLoss: 139.877881\n",
      "Train Epoch:73 [20000/60000 (33.333333%)]\tLoss: 143.025488\n",
      "Train Epoch:73 [40000/60000 (66.666667%)]\tLoss: 158.568916\n",
      "====> Epoch: 73 Average loss: 141.3332\n",
      "====> Evaluation loss : 141.1292\n",
      "Train Epoch:74 [0/60000 (0.000000%)]\tLoss: 145.027490\n",
      "Train Epoch:74 [20000/60000 (33.333333%)]\tLoss: 138.135039\n",
      "Train Epoch:74 [40000/60000 (66.666667%)]\tLoss: 142.625811\n",
      "====> Epoch: 74 Average loss: 140.2730\n",
      "====> Evaluation loss : 138.1826\n",
      "Train Epoch:75 [0/60000 (0.000000%)]\tLoss: 135.356055\n",
      "Train Epoch:75 [20000/60000 (33.333333%)]\tLoss: 130.893535\n",
      "Train Epoch:75 [40000/60000 (66.666667%)]\tLoss: 153.761230\n",
      "====> Epoch: 75 Average loss: 138.7956\n",
      "====> Evaluation loss : 136.9472\n",
      "Train Epoch:76 [0/60000 (0.000000%)]\tLoss: 135.171855\n",
      "Train Epoch:76 [20000/60000 (33.333333%)]\tLoss: 257.780859\n",
      "Train Epoch:76 [40000/60000 (66.666667%)]\tLoss: 165.210469\n",
      "====> Epoch: 76 Average loss: 161.6308\n",
      "====> Evaluation loss : 153.5653\n",
      "Train Epoch:77 [0/60000 (0.000000%)]\tLoss: 153.358398\n",
      "Train Epoch:77 [20000/60000 (33.333333%)]\tLoss: 145.580029\n",
      "Train Epoch:77 [40000/60000 (66.666667%)]\tLoss: 141.165879\n",
      "====> Epoch: 77 Average loss: 145.0847\n",
      "====> Evaluation loss : 138.5756\n",
      "Train Epoch:78 [0/60000 (0.000000%)]\tLoss: 142.085234\n",
      "Train Epoch:78 [20000/60000 (33.333333%)]\tLoss: 135.141094\n",
      "Train Epoch:78 [40000/60000 (66.666667%)]\tLoss: 126.527812\n",
      "====> Epoch: 78 Average loss: 139.0193\n",
      "====> Evaluation loss : 139.5796\n",
      "Train Epoch:79 [0/60000 (0.000000%)]\tLoss: 139.041455\n",
      "Train Epoch:79 [20000/60000 (33.333333%)]\tLoss: 129.526758\n",
      "Train Epoch:79 [40000/60000 (66.666667%)]\tLoss: 135.037168\n",
      "====> Epoch: 79 Average loss: 136.7532\n",
      "====> Evaluation loss : 135.4464\n",
      "Train Epoch:80 [0/60000 (0.000000%)]\tLoss: 139.278916\n",
      "Train Epoch:80 [20000/60000 (33.333333%)]\tLoss: 136.725625\n",
      "Train Epoch:80 [40000/60000 (66.666667%)]\tLoss: 127.454258\n",
      "====> Epoch: 80 Average loss: 139.3648\n",
      "====> Evaluation loss : 142.0151\n",
      "Train Epoch:81 [0/60000 (0.000000%)]\tLoss: 143.901074\n",
      "Train Epoch:81 [20000/60000 (33.333333%)]\tLoss: 143.473359\n",
      "Train Epoch:81 [40000/60000 (66.666667%)]\tLoss: 139.202607\n",
      "====> Epoch: 81 Average loss: 153.1090\n",
      "====> Evaluation loss : 183.6345\n",
      "Train Epoch:82 [0/60000 (0.000000%)]\tLoss: 181.087891\n",
      "Train Epoch:82 [20000/60000 (33.333333%)]\tLoss: 177.761680\n",
      "Train Epoch:82 [40000/60000 (66.666667%)]\tLoss: 170.597031\n",
      "====> Epoch: 82 Average loss: 173.0941\n",
      "====> Evaluation loss : 168.1747\n",
      "Train Epoch:83 [0/60000 (0.000000%)]\tLoss: 164.671953\n",
      "Train Epoch:83 [20000/60000 (33.333333%)]\tLoss: 165.317598\n",
      "Train Epoch:83 [40000/60000 (66.666667%)]\tLoss: 158.052363\n",
      "====> Epoch: 83 Average loss: 159.7432\n",
      "====> Evaluation loss : 155.0615\n",
      "Train Epoch:84 [0/60000 (0.000000%)]\tLoss: 153.791494\n",
      "Train Epoch:84 [20000/60000 (33.333333%)]\tLoss: 159.564033\n",
      "Train Epoch:84 [40000/60000 (66.666667%)]\tLoss: 144.041602\n",
      "====> Epoch: 84 Average loss: 153.3999\n",
      "====> Evaluation loss : 152.2555\n",
      "Train Epoch:85 [0/60000 (0.000000%)]\tLoss: 155.341172\n",
      "Train Epoch:85 [20000/60000 (33.333333%)]\tLoss: 154.989199\n",
      "Train Epoch:85 [40000/60000 (66.666667%)]\tLoss: 146.989043\n",
      "====> Epoch: 85 Average loss: 150.2073\n",
      "====> Evaluation loss : 147.7920\n",
      "Train Epoch:86 [0/60000 (0.000000%)]\tLoss: 144.121338\n",
      "Train Epoch:86 [20000/60000 (33.333333%)]\tLoss: 140.106338\n",
      "Train Epoch:86 [40000/60000 (66.666667%)]\tLoss: 141.328135\n",
      "====> Epoch: 86 Average loss: 147.7628\n",
      "====> Evaluation loss : 146.2820\n",
      "Train Epoch:87 [0/60000 (0.000000%)]\tLoss: 150.928428\n",
      "Train Epoch:87 [20000/60000 (33.333333%)]\tLoss: 143.089355\n",
      "Train Epoch:87 [40000/60000 (66.666667%)]\tLoss: 151.075234\n",
      "====> Epoch: 87 Average loss: 146.2473\n",
      "====> Evaluation loss : 145.8846\n",
      "Train Epoch:88 [0/60000 (0.000000%)]\tLoss: 149.558936\n",
      "Train Epoch:88 [20000/60000 (33.333333%)]\tLoss: 145.283730\n",
      "Train Epoch:88 [40000/60000 (66.666667%)]\tLoss: 136.252949\n",
      "====> Epoch: 88 Average loss: 151.5645\n",
      "====> Evaluation loss : 150.9883\n",
      "Train Epoch:89 [0/60000 (0.000000%)]\tLoss: 157.139316\n",
      "Train Epoch:89 [20000/60000 (33.333333%)]\tLoss: 136.612812\n",
      "Train Epoch:89 [40000/60000 (66.666667%)]\tLoss: 148.048936\n",
      "====> Epoch: 89 Average loss: 145.0912\n",
      "====> Evaluation loss : 143.6018\n",
      "Train Epoch:90 [0/60000 (0.000000%)]\tLoss: 141.367852\n",
      "Train Epoch:90 [20000/60000 (33.333333%)]\tLoss: 141.855391\n",
      "Train Epoch:90 [40000/60000 (66.666667%)]\tLoss: 138.134785\n",
      "====> Epoch: 90 Average loss: 143.2036\n",
      "====> Evaluation loss : 141.6814\n",
      "Train Epoch:91 [0/60000 (0.000000%)]\tLoss: 138.903359\n",
      "Train Epoch:91 [20000/60000 (33.333333%)]\tLoss: 139.020967\n",
      "Train Epoch:91 [40000/60000 (66.666667%)]\tLoss: 143.814902\n",
      "====> Epoch: 91 Average loss: 141.4034\n",
      "====> Evaluation loss : 142.1157\n",
      "Train Epoch:92 [0/60000 (0.000000%)]\tLoss: 148.368174\n",
      "Train Epoch:92 [20000/60000 (33.333333%)]\tLoss: 148.743926\n",
      "Train Epoch:92 [40000/60000 (66.666667%)]\tLoss: 152.190137\n",
      "====> Epoch: 92 Average loss: 142.4235\n",
      "====> Evaluation loss : 140.3322\n",
      "Train Epoch:93 [0/60000 (0.000000%)]\tLoss: 143.471807\n",
      "Train Epoch:93 [20000/60000 (33.333333%)]\tLoss: 131.373223\n",
      "Train Epoch:93 [40000/60000 (66.666667%)]\tLoss: 140.921680\n",
      "====> Epoch: 93 Average loss: 140.8063\n",
      "====> Evaluation loss : 139.1297\n",
      "Train Epoch:94 [0/60000 (0.000000%)]\tLoss: 145.274443\n",
      "Train Epoch:94 [20000/60000 (33.333333%)]\tLoss: 138.498574\n",
      "Train Epoch:94 [40000/60000 (66.666667%)]\tLoss: 129.458076\n",
      "====> Epoch: 94 Average loss: 138.6906\n",
      "====> Evaluation loss : 137.1614\n",
      "Train Epoch:95 [0/60000 (0.000000%)]\tLoss: 136.737158\n",
      "Train Epoch:95 [20000/60000 (33.333333%)]\tLoss: 137.476650\n",
      "Train Epoch:95 [40000/60000 (66.666667%)]\tLoss: 141.552295\n",
      "====> Epoch: 95 Average loss: 138.6925\n",
      "====> Evaluation loss : 139.2892\n",
      "Train Epoch:96 [0/60000 (0.000000%)]\tLoss: 148.495020\n",
      "Train Epoch:96 [20000/60000 (33.333333%)]\tLoss: 139.369971\n",
      "Train Epoch:96 [40000/60000 (66.666667%)]\tLoss: 130.558086\n",
      "====> Epoch: 96 Average loss: 136.7755\n",
      "====> Evaluation loss : 137.2440\n",
      "Train Epoch:97 [0/60000 (0.000000%)]\tLoss: 138.943232\n",
      "Train Epoch:97 [20000/60000 (33.333333%)]\tLoss: 127.229395\n",
      "Train Epoch:97 [40000/60000 (66.666667%)]\tLoss: 143.666074\n",
      "====> Epoch: 97 Average loss: 136.2415\n",
      "====> Evaluation loss : 135.0373\n",
      "Train Epoch:98 [0/60000 (0.000000%)]\tLoss: 138.962930\n",
      "Train Epoch:98 [20000/60000 (33.333333%)]\tLoss: 132.289531\n",
      "Train Epoch:98 [40000/60000 (66.666667%)]\tLoss: 135.773789\n",
      "====> Epoch: 98 Average loss: 134.8426\n",
      "====> Evaluation loss : 135.6821\n",
      "Train Epoch:99 [0/60000 (0.000000%)]\tLoss: 132.132695\n",
      "Train Epoch:99 [20000/60000 (33.333333%)]\tLoss: 132.018711\n",
      "Train Epoch:99 [40000/60000 (66.666667%)]\tLoss: 128.626719\n",
      "====> Epoch: 99 Average loss: 134.1944\n",
      "====> Evaluation loss : 134.5461\n",
      "Train Epoch:100 [0/60000 (0.000000%)]\tLoss: 134.021553\n",
      "Train Epoch:100 [20000/60000 (33.333333%)]\tLoss: 127.628477\n",
      "Train Epoch:100 [40000/60000 (66.666667%)]\tLoss: 137.414043\n",
      "====> Epoch: 100 Average loss: 132.6279\n",
      "====> Evaluation loss : 132.5930\n",
      "Train Epoch:101 [0/60000 (0.000000%)]\tLoss: 126.019404\n",
      "Train Epoch:101 [20000/60000 (33.333333%)]\tLoss: 132.777480\n",
      "Train Epoch:101 [40000/60000 (66.666667%)]\tLoss: 136.412012\n",
      "====> Epoch: 101 Average loss: 131.2326\n",
      "====> Evaluation loss : 133.2086\n",
      "Train Epoch:102 [0/60000 (0.000000%)]\tLoss: 139.105879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:102 [20000/60000 (33.333333%)]\tLoss: 135.744795\n",
      "Train Epoch:102 [40000/60000 (66.666667%)]\tLoss: 153.698457\n",
      "====> Epoch: 102 Average loss: 139.0070\n",
      "====> Evaluation loss : 135.0565\n",
      "Train Epoch:103 [0/60000 (0.000000%)]\tLoss: 135.543125\n",
      "Train Epoch:103 [20000/60000 (33.333333%)]\tLoss: 139.440156\n",
      "Train Epoch:103 [40000/60000 (66.666667%)]\tLoss: 132.971816\n",
      "====> Epoch: 103 Average loss: 135.5384\n",
      "====> Evaluation loss : 134.5070\n",
      "Train Epoch:104 [0/60000 (0.000000%)]\tLoss: 145.522207\n",
      "Train Epoch:104 [20000/60000 (33.333333%)]\tLoss: 150.885996\n",
      "Train Epoch:104 [40000/60000 (66.666667%)]\tLoss: 129.267988\n",
      "====> Epoch: 104 Average loss: 136.4206\n",
      "====> Evaluation loss : 132.9056\n",
      "Train Epoch:105 [0/60000 (0.000000%)]\tLoss: 130.750059\n",
      "Train Epoch:105 [20000/60000 (33.333333%)]\tLoss: 130.874580\n",
      "Train Epoch:105 [40000/60000 (66.666667%)]\tLoss: 144.994668\n",
      "====> Epoch: 105 Average loss: 136.4821\n",
      "====> Evaluation loss : 133.3910\n",
      "Train Epoch:106 [0/60000 (0.000000%)]\tLoss: 130.871016\n",
      "Train Epoch:106 [20000/60000 (33.333333%)]\tLoss: 144.607627\n",
      "Train Epoch:106 [40000/60000 (66.666667%)]\tLoss: 143.810234\n",
      "====> Epoch: 106 Average loss: 134.2079\n",
      "====> Evaluation loss : 136.0700\n",
      "Train Epoch:107 [0/60000 (0.000000%)]\tLoss: 129.172949\n",
      "Train Epoch:107 [20000/60000 (33.333333%)]\tLoss: 140.389307\n",
      "Train Epoch:107 [40000/60000 (66.666667%)]\tLoss: 132.413428\n",
      "====> Epoch: 107 Average loss: 140.9808\n",
      "====> Evaluation loss : 163.7609\n",
      "Train Epoch:108 [0/60000 (0.000000%)]\tLoss: 158.242949\n",
      "Train Epoch:108 [20000/60000 (33.333333%)]\tLoss: 148.758916\n",
      "Train Epoch:108 [40000/60000 (66.666667%)]\tLoss: 145.858018\n",
      "====> Epoch: 108 Average loss: 147.1605\n",
      "====> Evaluation loss : 140.7877\n",
      "Train Epoch:109 [0/60000 (0.000000%)]\tLoss: 133.894316\n",
      "Train Epoch:109 [20000/60000 (33.333333%)]\tLoss: 135.733818\n",
      "Train Epoch:109 [40000/60000 (66.666667%)]\tLoss: 140.960527\n",
      "====> Epoch: 109 Average loss: 142.0658\n",
      "====> Evaluation loss : 142.0564\n",
      "Train Epoch:110 [0/60000 (0.000000%)]\tLoss: 147.795732\n",
      "Train Epoch:110 [20000/60000 (33.333333%)]\tLoss: 136.481699\n",
      "Train Epoch:110 [40000/60000 (66.666667%)]\tLoss: 144.982119\n",
      "====> Epoch: 110 Average loss: 138.7807\n",
      "====> Evaluation loss : 138.5300\n",
      "Train Epoch:111 [0/60000 (0.000000%)]\tLoss: 133.157754\n",
      "Train Epoch:111 [20000/60000 (33.333333%)]\tLoss: 137.883252\n",
      "Train Epoch:111 [40000/60000 (66.666667%)]\tLoss: 131.543262\n",
      "====> Epoch: 111 Average loss: 140.6428\n",
      "====> Evaluation loss : 136.5687\n",
      "Train Epoch:112 [0/60000 (0.000000%)]\tLoss: 141.297607\n",
      "Train Epoch:112 [20000/60000 (33.333333%)]\tLoss: 131.570820\n",
      "Train Epoch:112 [40000/60000 (66.666667%)]\tLoss: 145.558701\n",
      "====> Epoch: 112 Average loss: 140.4554\n",
      "====> Evaluation loss : 133.6335\n",
      "Train Epoch:113 [0/60000 (0.000000%)]\tLoss: 134.245635\n",
      "Train Epoch:113 [20000/60000 (33.333333%)]\tLoss: 127.078047\n",
      "Train Epoch:113 [40000/60000 (66.666667%)]\tLoss: 129.188516\n",
      "====> Epoch: 113 Average loss: 133.8440\n",
      "====> Evaluation loss : 132.3180\n",
      "Train Epoch:114 [0/60000 (0.000000%)]\tLoss: 138.104121\n",
      "Train Epoch:114 [20000/60000 (33.333333%)]\tLoss: 134.894453\n",
      "Train Epoch:114 [40000/60000 (66.666667%)]\tLoss: 133.916396\n",
      "====> Epoch: 114 Average loss: 132.4899\n",
      "====> Evaluation loss : 135.6213\n",
      "Train Epoch:115 [0/60000 (0.000000%)]\tLoss: 134.603613\n",
      "Train Epoch:115 [20000/60000 (33.333333%)]\tLoss: 138.176250\n",
      "Train Epoch:115 [40000/60000 (66.666667%)]\tLoss: 126.942148\n",
      "====> Epoch: 115 Average loss: 132.4158\n",
      "====> Evaluation loss : 130.8733\n",
      "Train Epoch:116 [0/60000 (0.000000%)]\tLoss: 131.720840\n",
      "Train Epoch:116 [20000/60000 (33.333333%)]\tLoss: 162.490469\n",
      "Train Epoch:116 [40000/60000 (66.666667%)]\tLoss: 150.295576\n",
      "====> Epoch: 116 Average loss: 154.5836\n",
      "====> Evaluation loss : 142.0694\n",
      "Train Epoch:117 [0/60000 (0.000000%)]\tLoss: 151.543945\n",
      "Train Epoch:117 [20000/60000 (33.333333%)]\tLoss: 135.131357\n",
      "Train Epoch:117 [40000/60000 (66.666667%)]\tLoss: 132.807695\n",
      "====> Epoch: 117 Average loss: 140.8014\n",
      "====> Evaluation loss : 139.1034\n",
      "Train Epoch:118 [0/60000 (0.000000%)]\tLoss: 145.336797\n",
      "Train Epoch:118 [20000/60000 (33.333333%)]\tLoss: 135.874570\n",
      "Train Epoch:118 [40000/60000 (66.666667%)]\tLoss: 137.032285\n",
      "====> Epoch: 118 Average loss: 138.9045\n",
      "====> Evaluation loss : 134.8987\n",
      "Train Epoch:119 [0/60000 (0.000000%)]\tLoss: 139.308662\n",
      "Train Epoch:119 [20000/60000 (33.333333%)]\tLoss: 136.701758\n",
      "Train Epoch:119 [40000/60000 (66.666667%)]\tLoss: 139.603174\n",
      "====> Epoch: 119 Average loss: 134.7236\n",
      "====> Evaluation loss : 133.9726\n",
      "Train Epoch:120 [0/60000 (0.000000%)]\tLoss: 126.705566\n",
      "Train Epoch:120 [20000/60000 (33.333333%)]\tLoss: 164.815410\n",
      "Train Epoch:120 [40000/60000 (66.666667%)]\tLoss: 136.536504\n",
      "====> Epoch: 120 Average loss: 136.5777\n",
      "====> Evaluation loss : 133.0668\n",
      "Train Epoch:121 [0/60000 (0.000000%)]\tLoss: 138.424023\n",
      "Train Epoch:121 [20000/60000 (33.333333%)]\tLoss: 131.485371\n",
      "Train Epoch:121 [40000/60000 (66.666667%)]\tLoss: 129.766445\n",
      "====> Epoch: 121 Average loss: 141.4524\n",
      "====> Evaluation loss : 169.8946\n",
      "Train Epoch:122 [0/60000 (0.000000%)]\tLoss: 174.093320\n",
      "Train Epoch:122 [20000/60000 (33.333333%)]\tLoss: 148.579482\n",
      "Train Epoch:122 [40000/60000 (66.666667%)]\tLoss: 140.537920\n",
      "====> Epoch: 122 Average loss: 148.1555\n",
      "====> Evaluation loss : 135.6050\n",
      "Train Epoch:123 [0/60000 (0.000000%)]\tLoss: 140.430098\n",
      "Train Epoch:123 [20000/60000 (33.333333%)]\tLoss: 131.945820\n",
      "Train Epoch:123 [40000/60000 (66.666667%)]\tLoss: 132.896426\n",
      "====> Epoch: 123 Average loss: 133.7715\n",
      "====> Evaluation loss : 131.1660\n",
      "Train Epoch:124 [0/60000 (0.000000%)]\tLoss: 129.419492\n",
      "Train Epoch:124 [20000/60000 (33.333333%)]\tLoss: 125.083242\n",
      "Train Epoch:124 [40000/60000 (66.666667%)]\tLoss: 139.922627\n",
      "====> Epoch: 124 Average loss: 131.9212\n",
      "====> Evaluation loss : 129.4608\n",
      "Train Epoch:125 [0/60000 (0.000000%)]\tLoss: 132.075938\n",
      "Train Epoch:125 [20000/60000 (33.333333%)]\tLoss: 126.813105\n",
      "Train Epoch:125 [40000/60000 (66.666667%)]\tLoss: 133.570576\n",
      "====> Epoch: 125 Average loss: 130.1047\n",
      "====> Evaluation loss : 129.0694\n",
      "Train Epoch:126 [0/60000 (0.000000%)]\tLoss: 125.876328\n",
      "Train Epoch:126 [20000/60000 (33.333333%)]\tLoss: 125.154199\n",
      "Train Epoch:126 [40000/60000 (66.666667%)]\tLoss: 123.706025\n",
      "====> Epoch: 126 Average loss: 128.4393\n",
      "====> Evaluation loss : 128.4883\n",
      "Train Epoch:127 [0/60000 (0.000000%)]\tLoss: 128.005820\n",
      "Train Epoch:127 [20000/60000 (33.333333%)]\tLoss: 131.941016\n",
      "Train Epoch:127 [40000/60000 (66.666667%)]\tLoss: 129.490137\n",
      "====> Epoch: 127 Average loss: 128.1255\n",
      "====> Evaluation loss : 126.7608\n",
      "Train Epoch:128 [0/60000 (0.000000%)]\tLoss: 123.904863\n",
      "Train Epoch:128 [20000/60000 (33.333333%)]\tLoss: 132.496514\n",
      "Train Epoch:128 [40000/60000 (66.666667%)]\tLoss: 134.400234\n",
      "====> Epoch: 128 Average loss: 126.9699\n",
      "====> Evaluation loss : 125.2121\n",
      "Train Epoch:129 [0/60000 (0.000000%)]\tLoss: 124.078652\n",
      "Train Epoch:129 [20000/60000 (33.333333%)]\tLoss: 133.772676\n",
      "Train Epoch:129 [40000/60000 (66.666667%)]\tLoss: 137.492227\n",
      "====> Epoch: 129 Average loss: 131.0140\n",
      "====> Evaluation loss : 124.9036\n",
      "Train Epoch:130 [0/60000 (0.000000%)]\tLoss: 130.908848\n",
      "Train Epoch:130 [20000/60000 (33.333333%)]\tLoss: 139.191914\n",
      "Train Epoch:130 [40000/60000 (66.666667%)]\tLoss: 124.575527\n",
      "====> Epoch: 130 Average loss: 128.7984\n",
      "====> Evaluation loss : 128.5237\n",
      "Train Epoch:131 [0/60000 (0.000000%)]\tLoss: 129.067051\n",
      "Train Epoch:131 [20000/60000 (33.333333%)]\tLoss: 126.854795\n",
      "Train Epoch:131 [40000/60000 (66.666667%)]\tLoss: 121.610313\n",
      "====> Epoch: 131 Average loss: 124.9693\n",
      "====> Evaluation loss : 123.9460\n",
      "Train Epoch:132 [0/60000 (0.000000%)]\tLoss: 122.422695\n",
      "Train Epoch:132 [20000/60000 (33.333333%)]\tLoss: 127.112051\n",
      "Train Epoch:132 [40000/60000 (66.666667%)]\tLoss: 127.926084\n",
      "====> Epoch: 132 Average loss: 125.4733\n",
      "====> Evaluation loss : 124.8581\n",
      "Train Epoch:133 [0/60000 (0.000000%)]\tLoss: 123.362080\n",
      "Train Epoch:133 [20000/60000 (33.333333%)]\tLoss: 111.841094\n",
      "Train Epoch:133 [40000/60000 (66.666667%)]\tLoss: 126.395381\n",
      "====> Epoch: 133 Average loss: 125.0359\n",
      "====> Evaluation loss : 125.5405\n",
      "Train Epoch:134 [0/60000 (0.000000%)]\tLoss: 128.540488\n",
      "Train Epoch:134 [20000/60000 (33.333333%)]\tLoss: 127.606719\n",
      "Train Epoch:134 [40000/60000 (66.666667%)]\tLoss: 119.860518\n",
      "====> Epoch: 134 Average loss: 124.0203\n",
      "====> Evaluation loss : 122.0655\n",
      "Train Epoch:135 [0/60000 (0.000000%)]\tLoss: 123.837803\n",
      "Train Epoch:135 [20000/60000 (33.333333%)]\tLoss: 118.533105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:135 [40000/60000 (66.666667%)]\tLoss: 128.710010\n",
      "====> Epoch: 135 Average loss: 122.9564\n",
      "====> Evaluation loss : 122.8700\n",
      "Train Epoch:136 [0/60000 (0.000000%)]\tLoss: 129.655801\n",
      "Train Epoch:136 [20000/60000 (33.333333%)]\tLoss: 116.325977\n",
      "Train Epoch:136 [40000/60000 (66.666667%)]\tLoss: 121.728340\n",
      "====> Epoch: 136 Average loss: 122.1296\n",
      "====> Evaluation loss : 123.2038\n",
      "Train Epoch:137 [0/60000 (0.000000%)]\tLoss: 117.189365\n",
      "Train Epoch:137 [20000/60000 (33.333333%)]\tLoss: 114.849961\n",
      "Train Epoch:137 [40000/60000 (66.666667%)]\tLoss: 122.137793\n",
      "====> Epoch: 137 Average loss: 121.3809\n",
      "====> Evaluation loss : 119.6129\n",
      "Train Epoch:138 [0/60000 (0.000000%)]\tLoss: 121.444297\n",
      "Train Epoch:138 [20000/60000 (33.333333%)]\tLoss: 121.890332\n",
      "Train Epoch:138 [40000/60000 (66.666667%)]\tLoss: 126.097266\n",
      "====> Epoch: 138 Average loss: 120.5838\n",
      "====> Evaluation loss : 118.5706\n",
      "Train Epoch:139 [0/60000 (0.000000%)]\tLoss: 115.100938\n",
      "Train Epoch:139 [20000/60000 (33.333333%)]\tLoss: 123.882295\n",
      "Train Epoch:139 [40000/60000 (66.666667%)]\tLoss: 127.091602\n",
      "====> Epoch: 139 Average loss: 119.4851\n",
      "====> Evaluation loss : 127.2184\n",
      "Train Epoch:140 [0/60000 (0.000000%)]\tLoss: 135.781904\n",
      "Train Epoch:140 [20000/60000 (33.333333%)]\tLoss: 117.715215\n",
      "Train Epoch:140 [40000/60000 (66.666667%)]\tLoss: 120.343135\n",
      "====> Epoch: 140 Average loss: 119.1859\n",
      "====> Evaluation loss : 122.4073\n",
      "Train Epoch:141 [0/60000 (0.000000%)]\tLoss: 113.061973\n",
      "Train Epoch:141 [20000/60000 (33.333333%)]\tLoss: 117.778164\n",
      "Train Epoch:141 [40000/60000 (66.666667%)]\tLoss: 115.763398\n",
      "====> Epoch: 141 Average loss: 117.4532\n",
      "====> Evaluation loss : 121.7326\n",
      "Train Epoch:142 [0/60000 (0.000000%)]\tLoss: 121.825273\n",
      "Train Epoch:142 [20000/60000 (33.333333%)]\tLoss: 112.907598\n",
      "Train Epoch:142 [40000/60000 (66.666667%)]\tLoss: 116.207129\n",
      "====> Epoch: 142 Average loss: 116.9768\n",
      "====> Evaluation loss : 114.4874\n",
      "Train Epoch:143 [0/60000 (0.000000%)]\tLoss: 112.871084\n",
      "Train Epoch:143 [20000/60000 (33.333333%)]\tLoss: 107.084590\n",
      "Train Epoch:143 [40000/60000 (66.666667%)]\tLoss: 111.576348\n",
      "====> Epoch: 143 Average loss: 115.1553\n",
      "====> Evaluation loss : 113.2673\n",
      "Train Epoch:144 [0/60000 (0.000000%)]\tLoss: 112.403516\n",
      "Train Epoch:144 [20000/60000 (33.333333%)]\tLoss: 116.504717\n",
      "Train Epoch:144 [40000/60000 (66.666667%)]\tLoss: 130.983154\n",
      "====> Epoch: 144 Average loss: 115.1124\n",
      "====> Evaluation loss : 122.4866\n",
      "Train Epoch:145 [0/60000 (0.000000%)]\tLoss: 122.689473\n",
      "Train Epoch:145 [20000/60000 (33.333333%)]\tLoss: 117.859785\n",
      "Train Epoch:145 [40000/60000 (66.666667%)]\tLoss: 121.063672\n",
      "====> Epoch: 145 Average loss: 113.7419\n",
      "====> Evaluation loss : 112.1170\n",
      "Train Epoch:146 [0/60000 (0.000000%)]\tLoss: 106.577412\n",
      "Train Epoch:146 [20000/60000 (33.333333%)]\tLoss: 105.273203\n",
      "Train Epoch:146 [40000/60000 (66.666667%)]\tLoss: 126.689824\n",
      "====> Epoch: 146 Average loss: 112.3628\n",
      "====> Evaluation loss : 109.6151\n",
      "Train Epoch:147 [0/60000 (0.000000%)]\tLoss: 111.896055\n",
      "Train Epoch:147 [20000/60000 (33.333333%)]\tLoss: 114.402744\n",
      "Train Epoch:147 [40000/60000 (66.666667%)]\tLoss: 103.630186\n",
      "====> Epoch: 147 Average loss: 111.8868\n",
      "====> Evaluation loss : 109.1483\n",
      "Train Epoch:148 [0/60000 (0.000000%)]\tLoss: 108.741699\n",
      "Train Epoch:148 [20000/60000 (33.333333%)]\tLoss: 113.256865\n",
      "Train Epoch:148 [40000/60000 (66.666667%)]\tLoss: 114.646699\n",
      "====> Epoch: 148 Average loss: 110.6923\n",
      "====> Evaluation loss : 110.9928\n",
      "Train Epoch:149 [0/60000 (0.000000%)]\tLoss: 108.280645\n",
      "Train Epoch:149 [20000/60000 (33.333333%)]\tLoss: 114.522061\n",
      "Train Epoch:149 [40000/60000 (66.666667%)]\tLoss: 105.236250\n",
      "====> Epoch: 149 Average loss: 110.4568\n",
      "====> Evaluation loss : 108.9817\n",
      "Train Epoch:150 [0/60000 (0.000000%)]\tLoss: 116.482910\n",
      "Train Epoch:150 [20000/60000 (33.333333%)]\tLoss: 101.164033\n",
      "Train Epoch:150 [40000/60000 (66.666667%)]\tLoss: 105.200361\n",
      "====> Epoch: 150 Average loss: 109.3103\n",
      "====> Evaluation loss : 106.3666\n",
      "Train Epoch:151 [0/60000 (0.000000%)]\tLoss: 95.213057\n",
      "Train Epoch:151 [20000/60000 (33.333333%)]\tLoss: 105.829424\n",
      "Train Epoch:151 [40000/60000 (66.666667%)]\tLoss: 102.724180\n",
      "====> Epoch: 151 Average loss: 106.8675\n",
      "====> Evaluation loss : 107.2808\n",
      "Train Epoch:152 [0/60000 (0.000000%)]\tLoss: 101.892686\n",
      "Train Epoch:152 [20000/60000 (33.333333%)]\tLoss: 103.735527\n",
      "Train Epoch:152 [40000/60000 (66.666667%)]\tLoss: 92.496719\n",
      "====> Epoch: 152 Average loss: 106.3217\n",
      "====> Evaluation loss : 103.6560\n",
      "Train Epoch:153 [0/60000 (0.000000%)]\tLoss: 99.933115\n",
      "Train Epoch:153 [20000/60000 (33.333333%)]\tLoss: 110.655527\n",
      "Train Epoch:153 [40000/60000 (66.666667%)]\tLoss: 101.314629\n",
      "====> Epoch: 153 Average loss: 107.8504\n",
      "====> Evaluation loss : 105.4247\n",
      "Train Epoch:154 [0/60000 (0.000000%)]\tLoss: 106.678750\n",
      "Train Epoch:154 [20000/60000 (33.333333%)]\tLoss: 109.393789\n",
      "Train Epoch:154 [40000/60000 (66.666667%)]\tLoss: 107.160088\n",
      "====> Epoch: 154 Average loss: 106.7868\n",
      "====> Evaluation loss : 113.5772\n",
      "Train Epoch:155 [0/60000 (0.000000%)]\tLoss: 117.044600\n",
      "Train Epoch:155 [20000/60000 (33.333333%)]\tLoss: 104.670898\n",
      "Train Epoch:155 [40000/60000 (66.666667%)]\tLoss: 104.362656\n",
      "====> Epoch: 155 Average loss: 106.4731\n",
      "====> Evaluation loss : 106.6563\n",
      "Train Epoch:156 [0/60000 (0.000000%)]\tLoss: 103.547949\n",
      "Train Epoch:156 [20000/60000 (33.333333%)]\tLoss: 100.423867\n",
      "Train Epoch:156 [40000/60000 (66.666667%)]\tLoss: 107.664160\n",
      "====> Epoch: 156 Average loss: 104.5666\n",
      "====> Evaluation loss : 102.9561\n",
      "Train Epoch:157 [0/60000 (0.000000%)]\tLoss: 96.635029\n",
      "Train Epoch:157 [20000/60000 (33.333333%)]\tLoss: 103.543730\n",
      "Train Epoch:157 [40000/60000 (66.666667%)]\tLoss: 109.623232\n",
      "====> Epoch: 157 Average loss: 103.9982\n",
      "====> Evaluation loss : 102.8868\n",
      "Train Epoch:158 [0/60000 (0.000000%)]\tLoss: 104.318506\n",
      "Train Epoch:158 [20000/60000 (33.333333%)]\tLoss: 109.276309\n",
      "Train Epoch:158 [40000/60000 (66.666667%)]\tLoss: 96.687275\n",
      "====> Epoch: 158 Average loss: 102.8392\n",
      "====> Evaluation loss : 105.6048\n",
      "Train Epoch:159 [0/60000 (0.000000%)]\tLoss: 107.295098\n",
      "Train Epoch:159 [20000/60000 (33.333333%)]\tLoss: 105.273477\n",
      "Train Epoch:159 [40000/60000 (66.666667%)]\tLoss: 101.239199\n",
      "====> Epoch: 159 Average loss: 101.0078\n",
      "====> Evaluation loss : 101.4827\n",
      "Train Epoch:160 [0/60000 (0.000000%)]\tLoss: 97.294824\n",
      "Train Epoch:160 [20000/60000 (33.333333%)]\tLoss: 102.553789\n",
      "Train Epoch:160 [40000/60000 (66.666667%)]\tLoss: 93.564238\n",
      "====> Epoch: 160 Average loss: 99.5124\n",
      "====> Evaluation loss : 99.2240\n",
      "Train Epoch:161 [0/60000 (0.000000%)]\tLoss: 98.035938\n",
      "Train Epoch:161 [20000/60000 (33.333333%)]\tLoss: 95.047734\n",
      "Train Epoch:161 [40000/60000 (66.666667%)]\tLoss: 95.984219\n",
      "====> Epoch: 161 Average loss: 98.3998\n",
      "====> Evaluation loss : 97.5098\n",
      "Train Epoch:162 [0/60000 (0.000000%)]\tLoss: 97.717617\n",
      "Train Epoch:162 [20000/60000 (33.333333%)]\tLoss: 92.370908\n",
      "Train Epoch:162 [40000/60000 (66.666667%)]\tLoss: 97.281465\n",
      "====> Epoch: 162 Average loss: 96.0809\n",
      "====> Evaluation loss : 92.8083\n",
      "Train Epoch:163 [0/60000 (0.000000%)]\tLoss: 83.867100\n",
      "Train Epoch:163 [20000/60000 (33.333333%)]\tLoss: 78.375078\n",
      "Train Epoch:163 [40000/60000 (66.666667%)]\tLoss: 84.461289\n",
      "====> Epoch: 163 Average loss: 93.2574\n",
      "====> Evaluation loss : 95.0503\n",
      "Train Epoch:164 [0/60000 (0.000000%)]\tLoss: 101.791562\n",
      "Train Epoch:164 [20000/60000 (33.333333%)]\tLoss: 93.906680\n",
      "Train Epoch:164 [40000/60000 (66.666667%)]\tLoss: 94.264014\n",
      "====> Epoch: 164 Average loss: 91.8075\n",
      "====> Evaluation loss : 90.1595\n",
      "Train Epoch:165 [0/60000 (0.000000%)]\tLoss: 101.375977\n",
      "Train Epoch:165 [20000/60000 (33.333333%)]\tLoss: 107.008057\n",
      "Train Epoch:165 [40000/60000 (66.666667%)]\tLoss: 90.303594\n",
      "====> Epoch: 165 Average loss: 89.6512\n",
      "====> Evaluation loss : 86.2373\n",
      "Train Epoch:166 [0/60000 (0.000000%)]\tLoss: 87.590801\n",
      "Train Epoch:166 [20000/60000 (33.333333%)]\tLoss: 86.029658\n",
      "Train Epoch:166 [40000/60000 (66.666667%)]\tLoss: 90.026191\n",
      "====> Epoch: 166 Average loss: 87.4781\n",
      "====> Evaluation loss : 85.3278\n",
      "Train Epoch:167 [0/60000 (0.000000%)]\tLoss: 83.987090\n",
      "Train Epoch:167 [20000/60000 (33.333333%)]\tLoss: 81.662930\n",
      "Train Epoch:167 [40000/60000 (66.666667%)]\tLoss: 89.629453\n",
      "====> Epoch: 167 Average loss: 86.0788\n",
      "====> Evaluation loss : 83.1591\n",
      "Train Epoch:168 [0/60000 (0.000000%)]\tLoss: 89.939814\n",
      "Train Epoch:168 [20000/60000 (33.333333%)]\tLoss: 78.657217\n",
      "Train Epoch:168 [40000/60000 (66.666667%)]\tLoss: 89.137568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 168 Average loss: 85.1402\n",
      "====> Evaluation loss : 81.8840\n",
      "Train Epoch:169 [0/60000 (0.000000%)]\tLoss: 88.184619\n",
      "Train Epoch:169 [20000/60000 (33.333333%)]\tLoss: 87.017490\n",
      "Train Epoch:169 [40000/60000 (66.666667%)]\tLoss: 72.539395\n",
      "====> Epoch: 169 Average loss: 83.1685\n",
      "====> Evaluation loss : 80.6585\n",
      "Train Epoch:170 [0/60000 (0.000000%)]\tLoss: 82.178691\n",
      "Train Epoch:170 [20000/60000 (33.333333%)]\tLoss: 79.987148\n",
      "Train Epoch:170 [40000/60000 (66.666667%)]\tLoss: 88.772979\n",
      "====> Epoch: 170 Average loss: 81.8494\n",
      "====> Evaluation loss : 79.3610\n",
      "Train Epoch:171 [0/60000 (0.000000%)]\tLoss: 74.618408\n",
      "Train Epoch:171 [20000/60000 (33.333333%)]\tLoss: 87.100293\n",
      "Train Epoch:171 [40000/60000 (66.666667%)]\tLoss: 72.497363\n",
      "====> Epoch: 171 Average loss: 80.5863\n",
      "====> Evaluation loss : 77.9117\n",
      "Train Epoch:172 [0/60000 (0.000000%)]\tLoss: 71.051660\n",
      "Train Epoch:172 [20000/60000 (33.333333%)]\tLoss: 71.968486\n",
      "Train Epoch:172 [40000/60000 (66.666667%)]\tLoss: 83.105977\n",
      "====> Epoch: 172 Average loss: 78.6571\n",
      "====> Evaluation loss : 77.0451\n",
      "Train Epoch:173 [0/60000 (0.000000%)]\tLoss: 77.447881\n",
      "Train Epoch:173 [20000/60000 (33.333333%)]\tLoss: 91.167617\n",
      "Train Epoch:173 [40000/60000 (66.666667%)]\tLoss: 80.656748\n",
      "====> Epoch: 173 Average loss: 77.1588\n",
      "====> Evaluation loss : 74.3208\n",
      "Train Epoch:174 [0/60000 (0.000000%)]\tLoss: 63.914951\n",
      "Train Epoch:174 [20000/60000 (33.333333%)]\tLoss: 85.167217\n",
      "Train Epoch:174 [40000/60000 (66.666667%)]\tLoss: 73.487832\n",
      "====> Epoch: 174 Average loss: 76.2520\n",
      "====> Evaluation loss : 72.8181\n",
      "Train Epoch:175 [0/60000 (0.000000%)]\tLoss: 73.220859\n",
      "Train Epoch:175 [20000/60000 (33.333333%)]\tLoss: 81.922832\n",
      "Train Epoch:175 [40000/60000 (66.666667%)]\tLoss: 76.652471\n",
      "====> Epoch: 175 Average loss: 74.1666\n",
      "====> Evaluation loss : 72.2459\n",
      "Train Epoch:176 [0/60000 (0.000000%)]\tLoss: 66.466348\n",
      "Train Epoch:176 [20000/60000 (33.333333%)]\tLoss: 77.438340\n",
      "Train Epoch:176 [40000/60000 (66.666667%)]\tLoss: 64.029814\n",
      "====> Epoch: 176 Average loss: 74.1624\n",
      "====> Evaluation loss : 71.8713\n",
      "Train Epoch:177 [0/60000 (0.000000%)]\tLoss: 82.451514\n",
      "Train Epoch:177 [20000/60000 (33.333333%)]\tLoss: 76.041768\n",
      "Train Epoch:177 [40000/60000 (66.666667%)]\tLoss: 69.946064\n",
      "====> Epoch: 177 Average loss: 72.2102\n",
      "====> Evaluation loss : 68.5015\n",
      "Train Epoch:178 [0/60000 (0.000000%)]\tLoss: 74.272178\n",
      "Train Epoch:178 [20000/60000 (33.333333%)]\tLoss: 67.302285\n",
      "Train Epoch:178 [40000/60000 (66.666667%)]\tLoss: 70.394453\n",
      "====> Epoch: 178 Average loss: 70.9655\n",
      "====> Evaluation loss : 67.3255\n",
      "Train Epoch:179 [0/60000 (0.000000%)]\tLoss: 68.639648\n",
      "Train Epoch:179 [20000/60000 (33.333333%)]\tLoss: 71.427051\n",
      "Train Epoch:179 [40000/60000 (66.666667%)]\tLoss: 66.644727\n",
      "====> Epoch: 179 Average loss: 70.1648\n",
      "====> Evaluation loss : 68.2873\n",
      "Train Epoch:180 [0/60000 (0.000000%)]\tLoss: 68.584482\n",
      "Train Epoch:180 [20000/60000 (33.333333%)]\tLoss: 63.509160\n",
      "Train Epoch:180 [40000/60000 (66.666667%)]\tLoss: 69.217588\n",
      "====> Epoch: 180 Average loss: 67.8679\n",
      "====> Evaluation loss : 67.0788\n",
      "Train Epoch:181 [0/60000 (0.000000%)]\tLoss: 63.942246\n",
      "Train Epoch:181 [20000/60000 (33.333333%)]\tLoss: 60.722227\n",
      "Train Epoch:181 [40000/60000 (66.666667%)]\tLoss: 63.432529\n",
      "====> Epoch: 181 Average loss: 66.4836\n",
      "====> Evaluation loss : 66.9290\n",
      "Train Epoch:182 [0/60000 (0.000000%)]\tLoss: 68.200645\n",
      "Train Epoch:182 [20000/60000 (33.333333%)]\tLoss: 63.408379\n",
      "Train Epoch:182 [40000/60000 (66.666667%)]\tLoss: 57.542412\n",
      "====> Epoch: 182 Average loss: 64.1701\n",
      "====> Evaluation loss : 63.4746\n",
      "Train Epoch:183 [0/60000 (0.000000%)]\tLoss: 54.149043\n",
      "Train Epoch:183 [20000/60000 (33.333333%)]\tLoss: 76.867666\n",
      "Train Epoch:183 [40000/60000 (66.666667%)]\tLoss: 56.730381\n",
      "====> Epoch: 183 Average loss: 63.5655\n",
      "====> Evaluation loss : 70.1184\n",
      "Train Epoch:184 [0/60000 (0.000000%)]\tLoss: 60.737021\n",
      "Train Epoch:184 [20000/60000 (33.333333%)]\tLoss: 67.019395\n",
      "Train Epoch:184 [40000/60000 (66.666667%)]\tLoss: 57.832988\n",
      "====> Epoch: 184 Average loss: 61.6202\n",
      "====> Evaluation loss : 62.1404\n",
      "Train Epoch:185 [0/60000 (0.000000%)]\tLoss: 59.768643\n",
      "Train Epoch:185 [20000/60000 (33.333333%)]\tLoss: 58.801455\n",
      "Train Epoch:185 [40000/60000 (66.666667%)]\tLoss: 64.229541\n",
      "====> Epoch: 185 Average loss: 61.1665\n",
      "====> Evaluation loss : 58.2796\n",
      "Train Epoch:186 [0/60000 (0.000000%)]\tLoss: 54.385928\n",
      "Train Epoch:186 [20000/60000 (33.333333%)]\tLoss: 60.404150\n",
      "Train Epoch:186 [40000/60000 (66.666667%)]\tLoss: 47.242578\n",
      "====> Epoch: 186 Average loss: 60.2009\n",
      "====> Evaluation loss : 58.1481\n",
      "Train Epoch:187 [0/60000 (0.000000%)]\tLoss: 44.879600\n",
      "Train Epoch:187 [20000/60000 (33.333333%)]\tLoss: 62.289746\n",
      "Train Epoch:187 [40000/60000 (66.666667%)]\tLoss: 60.145264\n",
      "====> Epoch: 187 Average loss: 58.2897\n",
      "====> Evaluation loss : 56.8201\n",
      "Train Epoch:188 [0/60000 (0.000000%)]\tLoss: 62.478262\n",
      "Train Epoch:188 [20000/60000 (33.333333%)]\tLoss: 59.535674\n",
      "Train Epoch:188 [40000/60000 (66.666667%)]\tLoss: 61.436396\n",
      "====> Epoch: 188 Average loss: 56.4502\n",
      "====> Evaluation loss : 53.2903\n",
      "Train Epoch:189 [0/60000 (0.000000%)]\tLoss: 49.561992\n",
      "Train Epoch:189 [20000/60000 (33.333333%)]\tLoss: 50.584668\n",
      "Train Epoch:189 [40000/60000 (66.666667%)]\tLoss: 52.723418\n",
      "====> Epoch: 189 Average loss: 55.0513\n",
      "====> Evaluation loss : 51.6031\n",
      "Train Epoch:190 [0/60000 (0.000000%)]\tLoss: 50.093076\n",
      "Train Epoch:190 [20000/60000 (33.333333%)]\tLoss: 56.725088\n",
      "Train Epoch:190 [40000/60000 (66.666667%)]\tLoss: 56.202813\n",
      "====> Epoch: 190 Average loss: 55.4670\n",
      "====> Evaluation loss : 54.7607\n",
      "Train Epoch:191 [0/60000 (0.000000%)]\tLoss: 49.225068\n",
      "Train Epoch:191 [20000/60000 (33.333333%)]\tLoss: 57.893457\n",
      "Train Epoch:191 [40000/60000 (66.666667%)]\tLoss: 51.815771\n",
      "====> Epoch: 191 Average loss: 52.0166\n",
      "====> Evaluation loss : 52.4073\n",
      "Train Epoch:192 [0/60000 (0.000000%)]\tLoss: 45.341865\n",
      "Train Epoch:192 [20000/60000 (33.333333%)]\tLoss: 56.096514\n",
      "Train Epoch:192 [40000/60000 (66.666667%)]\tLoss: 51.832461\n",
      "====> Epoch: 192 Average loss: 53.1713\n",
      "====> Evaluation loss : 50.2706\n",
      "Train Epoch:193 [0/60000 (0.000000%)]\tLoss: 51.431826\n",
      "Train Epoch:193 [20000/60000 (33.333333%)]\tLoss: 51.261855\n",
      "Train Epoch:193 [40000/60000 (66.666667%)]\tLoss: 44.325635\n",
      "====> Epoch: 193 Average loss: 50.3258\n",
      "====> Evaluation loss : 49.2896\n",
      "Train Epoch:194 [0/60000 (0.000000%)]\tLoss: 47.636191\n",
      "Train Epoch:194 [20000/60000 (33.333333%)]\tLoss: 55.807334\n",
      "Train Epoch:194 [40000/60000 (66.666667%)]\tLoss: 46.312461\n",
      "====> Epoch: 194 Average loss: 49.4006\n",
      "====> Evaluation loss : 49.5073\n",
      "Train Epoch:195 [0/60000 (0.000000%)]\tLoss: 48.275283\n",
      "Train Epoch:195 [20000/60000 (33.333333%)]\tLoss: 46.711709\n",
      "Train Epoch:195 [40000/60000 (66.666667%)]\tLoss: 45.444355\n",
      "====> Epoch: 195 Average loss: 46.9895\n",
      "====> Evaluation loss : 45.2633\n",
      "Train Epoch:196 [0/60000 (0.000000%)]\tLoss: 47.962598\n",
      "Train Epoch:196 [20000/60000 (33.333333%)]\tLoss: 50.279326\n",
      "Train Epoch:196 [40000/60000 (66.666667%)]\tLoss: 62.444355\n",
      "====> Epoch: 196 Average loss: 56.3068\n",
      "====> Evaluation loss : 53.9032\n",
      "Train Epoch:197 [0/60000 (0.000000%)]\tLoss: 53.281787\n",
      "Train Epoch:197 [20000/60000 (33.333333%)]\tLoss: 55.130225\n",
      "Train Epoch:197 [40000/60000 (66.666667%)]\tLoss: 52.140361\n",
      "====> Epoch: 197 Average loss: 52.9581\n",
      "====> Evaluation loss : 53.5743\n",
      "Train Epoch:198 [0/60000 (0.000000%)]\tLoss: 54.096318\n",
      "Train Epoch:198 [20000/60000 (33.333333%)]\tLoss: 47.471602\n",
      "Train Epoch:198 [40000/60000 (66.666667%)]\tLoss: 49.269551\n",
      "====> Epoch: 198 Average loss: 84.1942\n",
      "====> Evaluation loss : 206.1409\n",
      "Train Epoch:199 [0/60000 (0.000000%)]\tLoss: 208.645371\n",
      "Train Epoch:199 [20000/60000 (33.333333%)]\tLoss: 156.181953\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-43f8f325e823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0meval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meval_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c6fa037f5eaf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mrecon_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_sigmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_sigmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6c5356686386>\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(recon_x, x, mu, log_var, z_sigmas, eps_0, z)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# reconstruction loss : binary cross entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# logp(x|z)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbce_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# -logp(z)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/envs/base/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2523\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m     return torch._C._nn.binary_cross_entropy(\n\u001b[0m\u001b[1;32m   2526\u001b[0m         input, target, weight, reduction_enum)\n\u001b[1;32m   2527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "best_loss = float('inf')\n",
    "for epoch in range(1, 200):\n",
    "    train(epoch)\n",
    "    eval_loss = evaluation()\n",
    "    if eval_loss < best_loss:\n",
    "        torch.save(vae.state_dict(), 'iaf_vae_best.pth')\n",
    "        best_loss = eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opened-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_state_dict(torch.load('iaf_vae_best.pth'))\n",
    "_ = vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chemical-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_ind, (data, _) in enumerate(eval_loader):\n",
    "#             data = data.cuda()\n",
    "        \n",
    "        data = data.view(BATCH_SIZE, -1)\n",
    "        recon_batch, *_ = vae(data)\n",
    "        n = min(data.size(0), 8)\n",
    "        comparison = torch.cat([data[:n].view(8, 1, 28, 28)[:n],\n",
    "                                    recon_batch.unsqueeze(-1).view(BATCH_SIZE, 1, 28, 28)[:n]])\n",
    "        save_image(comparison.data.cpu(),\n",
    "                       'samples/sample_comp_iaf' +'.png', nrow=n)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "working-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(64, 2)\n",
    "    sample = vae.dec(z).view(64, 1, 28, 28)\n",
    "    save_image(sample.data.cpu(), 'samples/sample_iaf.png', nrow=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-isaac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
